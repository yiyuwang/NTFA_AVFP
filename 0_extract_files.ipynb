{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "107e6319",
   "metadata": {},
   "source": [
    "# Saving Reconstruction from NTFA into nii files\n",
    "\n",
    "Yiyu Wang\n",
    "\n",
    "2023/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0088e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "HTFATorch                /home/wang.yiyu/.conda/envs/HTFATorch\n",
      "NTFA_env3             *  /home/wang.yiyu/.conda/envs/NTFA_env3\n",
      "base                     /shared/centos7/anaconda3/3.7\n",
      "                         /work/abslab/Yiyu/DNN_env\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# check we're in our env (*)\n",
    "%conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a8904a-c364-49b1-b05c-76433e9418e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import plotting, image\n",
    "import nibabel as nib\n",
    "import itertools\n",
    "\n",
    "mask_dir = 'masks/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39a35656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTFA code from: /work/abslab/NTFA_packages/NTFADegeneracy_merged/\n",
      "['100', '103', '104', '105', '106', '107', '108', '109', '111', '112', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '127', '128', '130', '131', '132', '134', '135', '136', '137', '138', '139', '140', '142', '143', '144', '145', '146', '149', '150', '151', '152', '153', '154', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '169', '170', '171', '172', '174', '175', '176', '177', '179', '181', '182', '183', '184', '185', '186']\n",
      "total subs = 71\n",
      "using mask:  /work/abslab/AVFP/NTFA/masks/GM_fmriprep_novelgroup_mask_N71.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# **** parameters that define the model directory ******\n",
    "# path for the NTFA package\n",
    "which_ntfa_model = 'v2'\n",
    "\n",
    "NTFA_path = \"NTFA_v2/\"\n",
    "print(\"NTFA code from:\", NTFA_path)\n",
    "import sys\n",
    "sys.path.append(NTFA_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subs = 'All' #20 #'All' #note, database file must have been created already for these subjects\n",
    "\n",
    "included_data = pd.read_csv(base_dir + 'fmri_info/included_avfp_subjects.csv', header=None)\n",
    "subIDs = included_data[0].astype('str').tolist()\n",
    "print(subIDs)\n",
    "total_subs = len(subIDs)\n",
    "print(f\"total subs = {total_subs}\")\n",
    "\n",
    "# using GM (and SNR) or SNR only?\n",
    "mask_type = 'GMgroup'\n",
    "# load mask:\n",
    "if mask_type == 'GMgroup':\n",
    "    mask_file = mask_dir +f'GM_fmriprep_novelgroup_mask_N71.nii.gz'\n",
    "else:\n",
    "    mask_file = mask_dir + 'gm_mask_icbm152_brain.nii.gz'\n",
    "\n",
    "print('using mask: ', mask_file)\n",
    "\n",
    "\n",
    "# penalty weights (participant, stimulus, combination)\n",
    "p_weight, s_weight, c_weight = 1, 1, 1\n",
    "linear_opts = 'None' # 'C', 'PSC' 'None'\n",
    "# additional parameters:\n",
    "n_epoch = 2000\n",
    "n_factor = 100\n",
    "n_check = 50 #\n",
    "\n",
    "# load mask:\n",
    "mask = image.load_img(mask_file)\n",
    "mask_data = mask.get_fdata()\n",
    "\n",
    "SEED = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ca0d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching model from:  models/AVFP_NTFA_sub-All_epoch-2000_factor-500_mask-GMgroup_111_lin-None_ntfa-v2_visreg/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up directory and filename for saving model\n",
    "\n",
    "\n",
    "query_dir = f'models/AVFP_NTFA_sub-{subs}_epoch-{n_epoch}_factor-{n_factor}_mask-{mask_type}_{p_weight}{s_weight}{c_weight}_lin-{linear_opts}_ntfa-{which_ntfa_model}_visreg/'\n",
    "\n",
    "print(\"\\nFetching model from: \", query_dir,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0727f9e6-77b9-4082-8a20-df04f87f444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ntfa functions\n",
    "import htfa_torch.dtfa as DTFA\n",
    "import htfa_torch.niidb as niidb\n",
    "import htfa_torch.utils as utils\n",
    "import htfa_torch.tardb as tardb\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed37560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching database: /work/abslab/Yiyu/NTFA_AVFP/data/AVFP_NTFA_N-71_mask-GMgroup.tar\n"
     ]
    }
   ],
   "source": [
    "# define database filename\n",
    "\n",
    "AVFP_FILE = f'data/AVFP_NTFA_N-{total_subs}_mask-{mask_type}.tar'\n",
    "print('\\nFetching database:',AVFP_FILE)\n",
    "\n",
    "\n",
    "# this step can take a few minutes (15min for avfp ~2556 trials)\n",
    "avfp_db = tardb.FmriTarDataset(AVFP_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735b3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the DTFA object for avfp_database\n",
    "# again depending on the data size, it can take sometime\n",
    "dtfa = DTFA.DeepTFA(avfp_db, num_factors=n_factor, linear_params=linear_opts, query_name=query_dir)\n",
    "n_blocks = dtfa.num_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ffcce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading most recent checkpoint: models/AVFP_NTFA_sub-All_epoch-2000_factor-500_mask-GMgroup_111_lin-None_ntfa-v2_visreg/CHECK_06042023_192120_Epoch1085 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the most recent model (prefix for .dtfa_model and .dtfa_guide)\n",
    "checkpoint_files = glob.glob(query_dir + 'CHECK*dtfa*')\n",
    "state_name = max(checkpoint_files, key=os.path.getctime).split('.dtfa')[0]\n",
    "print('\\nLoading most recent checkpoint:',state_name,'\\n')\n",
    "\n",
    "dtfa.load_state(state_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab844b4",
   "metadata": {},
   "source": [
    "# Create Nii for original activations and reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852c52f-24b7-41ac-9fd6-b127b5696175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this process can take about 1-2 hours\n",
    "for block_i in range(n_blocks):\n",
    "    # get block info:\n",
    "    tr = dtfa._dataset.blocks[block_i]\n",
    "    file_name = f\"sub-{tr['subject']}_run-{tr['run']}_video-{tr['task']}.nii.gz\"\n",
    "\n",
    "    # print progress\n",
    "    if block_i % 50 ==0:\n",
    "        print(block_i)\n",
    "    \n",
    "    # extract reconstructions:\n",
    "    if os.path.exists(os.path.join(query_dir, 'reconstruction/'+ file_name)):\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        # dtfa.results contain information about the factor weights and locations\n",
    "        results = dtfa.results(block=block_i, generative=True)\n",
    "        # calculate reconstruction:\n",
    "        recon = (results['weights'] @ results['factors']).numpy()\n",
    "        recon = np.mean(recon, axis=0, keepdims=True) \n",
    "        #to nifti image\n",
    "        recon_brain_image = utils.cmu2nii(recon,\n",
    "                              dtfa.voxel_locations.numpy(),\n",
    "                              tr['template'])\n",
    "        nib.save(recon_brain_image, os.path.join(query_dir, 'reconstruction/'+ file_name))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d3ac4-0535-4a32-b2a7-9ae209ba36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block_i in range(n_blocks):\n",
    "\n",
    "    # get block info\n",
    "    tr = dtfa._dataset.blocks[block_i]\n",
    "    file_name = f\"sub-{tr['subject']}_run-{tr['run']}_video-{tr['task']}.nii.gz\"\n",
    "\n",
    "    # print progress\n",
    "    if block_i % 50 ==0:\n",
    "        print(block_i)\n",
    "\n",
    "    # extract activations     \n",
    "    if os.path.exists(os.path.join(query_dir, 'activations/'+ file_name)):\n",
    "        continue\n",
    "    else:\n",
    "        #get the original activations that were used for ntfa training\n",
    "        # dtfa_tr contain each block neural data from dtfa._dataset\n",
    "        activations = dtfa._dataset[block_i]['activations'].numpy()\n",
    "        activations = np.mean(activations, axis = 0, keepdims = True)\n",
    "\n",
    "        act_brain_image = utils.cmu2nii(activations,\n",
    "                              dtfa.voxel_locations.numpy(),\n",
    "                              tr['template'])\n",
    "        nib.save(act_brain_image, os.path.join(query_dir, 'activations/'+ file_name))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6302f-6355-4bbb-bbea-4ecb3948b82e",
   "metadata": {},
   "source": [
    "# create embedding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3a79a-60c9-4bb3-abca-c644e45534ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_embeddings_v1(): \n",
    "    hyperparams = dtfa.variational.hyperparams.state_vardict()\n",
    "    tasks = dtfa.tasks()\n",
    "    subjects = dtfa.subjects()\n",
    "    z_p_mu = hyperparams['subject_weight']['mu'].data\n",
    "    z_s_mu = hyperparams['task']['mu'].data\n",
    "\n",
    "    z_ps_mu, combinations = list(), list()\n",
    "    for p in range(len(subjects)):\n",
    "        # because I coded by memory, participants only have 1/2 of the unqiue tasks each - find index:\n",
    "        sub_tasks = [b['task'] for b in avfp_db.blocks.values() if b['subject'] == subjects[p]]\n",
    "        combinations.append(np.vstack([np.repeat(subjects[p],len(sub_tasks)), np.array(sub_tasks)]))\n",
    "        for t in range(len(sub_tasks)):\n",
    "            task_index = [i for i, e in enumerate(tasks) if e == sub_tasks[t]]\n",
    "            joint_embed = torch.cat((z_p_mu[p], z_s_mu[task_index[0]]), dim=-1)\n",
    "            interaction_embed = dtfa.decoder.interaction_embedding(joint_embed).data\n",
    "            z_ps_mu.append(interaction_embed.data.numpy())\n",
    "    z_ps_mu = np.vstack(z_ps_mu)   \n",
    "    combinations = np.hstack(combinations).T  \n",
    "\n",
    "    # convert to dataframes\n",
    "    z_p = pd.DataFrame(np.hstack([np.reshape(subjects, (len(subjects),1)), z_p_mu.numpy()]),\n",
    "                       columns=['participant','x','y'])\n",
    "    z_s = pd.DataFrame(np.hstack([np.reshape(tasks, (len(tasks),1)), z_s_mu.numpy()]),\n",
    "                       columns=['stimulus','x','y'])\n",
    "    z_ps = pd.DataFrame(np.hstack([combinations, z_ps_mu]),\n",
    "                        columns=['participant','stimulus','x','y'])\n",
    "    return z_p, z_s, z_ps\n",
    "\n",
    "def fetch_embeddings_v2(): \n",
    "    hyperparams = dtfa.variational.hyperparams.state_vardict()\n",
    "    tasks = dtfa.tasks()\n",
    "    subjects = dtfa.subjects()\n",
    "    interactions = dtfa._interactions\n",
    "    z_p_mu = hyperparams['subject_weight']['mu'].data\n",
    "    z_s_mu = hyperparams['task']['mu'].data\n",
    "    z_i_mu = hyperparams['interaction']['mu'].data\n",
    "    \n",
    "    z_p_sigma = torch.exp(hyperparams['subject_weight']['log_sigma'].data)\n",
    "    z_s_sigma = torch.exp(hyperparams['task']['log_sigma'].data)\n",
    "    z_i_sigma = torch.exp(hyperparams['interaction']['log_sigma'].data)\n",
    "\n",
    "    # convert to dataframes\n",
    "    z_p = pd.DataFrame(np.hstack([np.reshape(subjects, (len(subjects),1)), z_p_mu.numpy(), z_p_sigma.numpy()]),\n",
    "                       columns=['participant','x','y', 'x_sigma','y_sigma'])\n",
    "    z_s = pd.DataFrame(np.hstack([np.reshape(tasks, (len(tasks),1)), z_s_mu.numpy(), z_s_sigma.numpy()]),\n",
    "                       columns=['stimulus','x','y', 'x_sigma', 'y_sigma'])\n",
    "    z_ps = pd.DataFrame(np.hstack([interactions, z_i_mu.numpy(), z_i_sigma.numpy()]),\n",
    "                        columns=['participant','stimulus','x','y', 'x_sigma', 'y_sigma'])\n",
    "    return z_p, z_s, z_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dc154-db37-4c62-a4a3-cbb579bf1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the most recent model (prefix for .dtfa_model and .dtfa_guide)\n",
    "checkpoint_files = glob.glob(query_dir + 'CHECK*dtfa*')\n",
    "state_name = max(checkpoint_files, key=os.path.getctime).split('.dtfa')[0]\n",
    "print('\\nLoading most recent checkpoint:',state_name,'\\n')\n",
    "\n",
    "dtfa.load_state(state_name)\n",
    "if which_ntfa_model == 'v1': \n",
    "    p_embedding, s_embedding, c_embedding = fetch_embeddings_v1()\n",
    "elif which_ntfa_model == 'v2': \n",
    "    p_embedding, s_embedding, c_embedding = fetch_embeddings_v2()\n",
    "else:\n",
    "    raise Exception(\"Specify or check the NTFA version you are running!\")\n",
    "\n",
    "p_embedding.participant = p_embedding.participant.astype('int').astype('string')\n",
    "p_embedding[['x','y']] = p_embedding[['x','y']].astype('float')\n",
    "\n",
    "s_embedding[['x','y']] = s_embedding[['x','y']].astype('float')\n",
    "\n",
    "c_embedding.participant = c_embedding.participant.astype('int').astype('string')\n",
    "c_embedding[['x','y']] = c_embedding[['x','y']].astype('float')\n",
    "\n",
    "# save embedding information in pickle\n",
    "p_embedding.to_pickle(query_dir + 'p_embedding.pkl')\n",
    "s_embedding.to_pickle(query_dir + 's_embedding.pkl')\n",
    "c_embedding.to_pickle(query_dir + 'c_embedding.pkl')\n",
    "print(\"\\nNew embedding pkl created at: \", query_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
